[README-whisper.md](https://github.com/user-attachments/files/21696774/README-whisper.md)
# Fine-Tuning Whisper for Arabic ASR
This repo contains code only; datasets and checkpoints are not included.
This repository contains code for **two-stage fine-tuning** of OpenAI's **Whisper** model for Arabic Automatic Speech Recognition (ASR), including Modern Standard Arabic and various dialects.

## ğŸ“Œ Overview
The fine-tuning process was conducted in two stages:
1. **First Stage of Fine-Tuning** â€“ Fine-tuned Whisper on the Common Voice Arabic dataset.
2. **Second Stage of Fine-Tuning (Resumed on Different Dataset)** â€“ Took the best checkpoint from Stage 1 and continued fine-tuning on the MASC dataset.

Both stages were evaluated on **Flures**, an unseen dataset, to measure generalization ability.

---

## ğŸ“‚ Repository Structure
```
.
â”œâ”€â”€ First_Stage_Fine-tuning_Whisper.py   # Fine-tuning on Common Voice (Stage 1)
â”œâ”€â”€ Second_Stage_Fine-tuning_Whisper.py  # Continued fine-tuning on MASC (Stage 2)
â”œâ”€â”€ requirements.txt                     # Dependencies list
â””â”€â”€ README.md                            # Project documentation
```

---

## âš™ï¸ Features
- **Two-stage fine-tuning** pipeline for improved ASR performance.
- **Dataset loading** from structured JSON and audio folders.
- **Arabic text normalization** with Whisperâ€™s normalizer and custom refinements.
- **LoRA integration** for efficient training.
- **Multi-GPU training** with Hugging Face Accelerate.
- **Evaluation metrics**:
  - **WER** (Word Error Rate)
  - **CER** (Character Error Rate)

---

## ğŸ“Š Evaluation Metrics
- **Word Error Rate (WER)**: Measures word-level transcription accuracy.
- **Character Error Rate (CER)**: Measures character-level accuracy â€” useful for morphologically rich languages.

---

## ğŸš€ Usage

### 1. Install dependencies
```bash
pip install -r requirements.txt
```

### 2. Prepare dataset
The dataset should follow this structure:
```
dataset/
â”‚
â”œâ”€â”€ file1.json
â”œâ”€â”€ file2.json
â””â”€â”€ audio_folder/
    â”œâ”€â”€ audio1.wav
    â”œâ”€â”€ audio2.wav
    â””â”€â”€ ...
```
Each JSON file should include:
```json
{
    "vid": "video_id",
    "segments": [
        {"file_name": "audio1.wav", "transcription": "Arabic text..."},
        {"file_name": "audio2.wav", "transcription": "Arabic text..."}
    ]
}
```

### 3. Run fine-tuning
```bash
python First_Stage_Fine-tuning_Whisper.py
```

### 4. Resume from Stage 1 checkpoint (Stage 2 fine-tuning)
```bash
python Second_Stage_Fine-tuning_Whisper.py
```

---

## ğŸ“ˆ Results on Flures (Unseen Dataset)

| Stage                                     | WER (%) | CER  |
|-------------------------------------------|---------|------|
| First Stage Fine-Tuning (Common Voice)    | 10.0    | 0.036|
| Second Stage Fine-Tuning (Resumed on MASC)| 9.7     | 0.033|

*Flures dataset was not seen during training and used solely for evaluation.*

---

## ğŸ›  Requirements
- Python 3.9+
- PyTorch (GPU recommended)
- Hugging Face Transformers
- Datasets
- Accelerate
- JiWER

---

## ğŸ“„ License
 Thi project is intended license under the MIT License.
